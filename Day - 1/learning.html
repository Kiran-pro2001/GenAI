<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <h1>Gen AI</h1>
    <ol>
        <li> Gen AI - Generative AI - it generates content based on the past data set that it gets trained. </li>
        <li>At the end, these AI Modles are just <mark>predicting</mark> the output.</li>
        <li>Whatever input we give, it gets first <strong>tokenize</strong>, it means machine don't understand words, since it can be any language very difficult & confusion for the machine to understnad, so it gets converted to number (based on different ML model it do accordingly), some are doing words wise, some are collection of words, some are snetence basis, and based on the all tokens, the AI Modle will predict the next output </li>
        <li>Let's take an example, 1,2,3,4,?  - To get the next answer, we can direclty predict that 5. Now how we are doing is?, Just we understand the pattern. Same AI also do the precition based on the data set it gets trained. If you just ask the Chat GPT, what is 2+2, it will not be able to calculate it, just ask do it without using any external tool ,just be pure LLM Model.</li>
        <li>So, LLM Model can't calculate. LLM Model can't run your program. <i>LLM Model can only predict based on the datat it gets trained.</i></li>
        <li>Now, the more data it gets trained, it's prediction become more accurate, like if I ask what is 7+5, you can directly tell 12, not by calculating it, but by doing this again again, you get train to it. Same way, AI Models can't calcualte, it just predicts. And it's prediction is becoming more accurate, that we are thingking that it is calculating it.</li>
        <li>Never think that, LLM Modle have answer for each single questions. Each time we ask any questions, on the backend, it first converts to a tokens (using the process of tokenization), and then LLM try to understand the hideen pattern between those numbers, every time maybe LLM can understand the different patterns, so might be you got different results.</li>
        <li>As like, 1,2,4,?  -- now the next number can be 8 or 7. Now both can be answered based on the which pattern it understand first. </li>
        <li>Chat GPT - Generative Pretrained Transformer.-- it generate, it is already pre trained, and it can transform data into different formats like text/image/audio/video </li>
        <li>If LLM Model don't know anything about any topic, then also it can predict. </li>
        <li></li>
    </ol>

    <br>
</body>
</html>